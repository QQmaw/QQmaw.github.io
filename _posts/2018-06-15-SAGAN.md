---
# Posts need to have the `post` layout
layout: post
comments: true

# The title of your post
title: SA-GAN 介紹 - Self-Attention Generative Adversarial Networks

# (Optional) Write a short (~150 characters) description of each blog post.
# This description is used to preview the page on search engines, social media, etc.
description: >
  Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena, ["Self-Attention Generative Adversarial Networks"](https://arxiv.org/abs/1805.08318)arXiv:1805.08318



# (Optional) Link to an image that represents your blog post.
# The aspect ratio should be ~16:9.
image: /assets/img/default.jpg

# You can hide the description and/or image from the output
# (only visible to search engines) by setting:
# hide_description: true
# hide_image: true

# (Optional) Each post can have zero or more categories, and zero or more tags.
# The difference is that categories will be part of the URL, while tags will not.
# E.g. the URL of this post is <site.baseurl>/hydejack/2017/11/23/example-content/
categories: [Deep Learning, Computer Vision]
tags: []
# If you want a category or tag to have its own page,
# check out `_featured_categories` and `_featured_tags` respectively.
---
Paper:Self-Attention-GAN，

這篇目前還沒發到conference中，

因為他 2018 May 21 才發佈到arxiv，

此文的撰稿時間為 2018 Apr 15，

單純是因為我對這主題有興趣，

所以才看這篇的，

不過我覺得這篇之後應該也能投到挺好的conference。

作者有將程式碼釋出 [Github](https://github.com/heykeetae/Self-Attention-GAN)

# 簡介

SA-GAN透過Attention的機制，

可以知道我們在一張圖片中是在focus在哪個部分，

不僅如此，也透過Attention解決了大範圍區域偵測的問題。

SA-GAN透過上述的優點，在圖像生成（Image synthesis）的任務中達到了不錯的分數。

除了在Generator可以產生不錯的圖片之外，

在Discriminator中也可以透過Attention的機制，

偵測到細節部分，促使Generator model變得更好。



# CNN對於圖像生成的問題

如果你有認真的看過一些圖像生成的任務，

通常會發現背景都處理得不好，

儘管你的生成目標做得不錯(e.g.人臉 or 動物

但是如果圖片有這種大範圍(long range)區塊(e.g.顏色 or 背景（天空）

往往這種部份生成的會不好。

因為CNN是透過filter(3X3 or 5X5的kernal size)經由sliding windows的概念，

然後透過每個filter學習特徵，

可以想到的透過這種方式學習，

當要處理大範圍的影像時，

並不是一層layer可以處理的，

因為通常需要好幾層layer一起做搭配才能夠偵測出大範圍的區塊。（這也代表了訓練的困難性。

也因此可以想像到，為什麼long range的偵測是多麼的困難。



# Attention 優勢

透過Attention可以偵測大範圍(long range)區塊，

我們先看一下成果圖片 感覺一下

![](/assets/img/2018-06-15-SAGAN/Attention-result.png)

看到上方圖片的紅色框框那張圖，

其實他那個Attention就是在找後面藍色的背景，

可以看到做得不錯，

重要的是竟然可以繞過去狗的頭！！

他的特點就是，透過利用鄰居（附近的pixel

去做attention！


# model架構

![](/assets/img/2018-06-15-SAGAN/model.png)

這邊比較值得一提的應該是 "X" matrix multiplication

大家可能會不知道為什麼要把feature map做相X的動作。

這邊大家可能會想說經過f(x) / g(x) / h(x)出來的是 C X H X W

> C = Channel size
> 
> H = image height
> 
> W = image width
> 
> 那 H X W 和 H X W 相乘， 想不通到底在幹嘛。
>
> 而這邊我看github code 其實是將 N = H X W
>
> 所以目前的圖片已經被展開了，變成  C, N
> 
> 那之為什麼轉置也很明顯了，
> 
> 就是基於C（每個不同的feature map），對每個pixel做相乘，（想成兩個同樣維度的vector如果要相乘那有一個要轉置transpose。）

![](/assets/img/2018-06-15-SAGAN/form-1.png)
![](/assets/img/2018-06-15-SAGAN/form-2.png)

在公式(3)，也給了一個很有趣的想法，

r 一開始為0， 慢慢的才會給權重，

因為一開始的attention很爛，要慢慢的讓他學，比重會越來越高。

# 這篇揭露GAN穩定的tricks

### [Spectral normalization for both generator and discriminator]

	
ICLR 2018的 Spectral normalizarion for generative adversarial network.

簡單來說就是比BN更新的方法，

概念就是不透過參數，可以讓整個layer的spectral norm的權重為1

在[Spectral normalization openreview]中，挺多人回應的，看起來是真的不錯用。

不過原本Spectral適用於Discriminator，

這邊他說其實SN用於Generator也可以。


### [Gans trained by a two time-scale update rule converge to a local nash equilibrium]

NIPS 2017的Gans trained by a two time-scale update rule converge to a local nash equilibrium

論文裡面滿滿的數學。

簡單來說，以往GAN比較常用的trick是discriminator每訓練個5次，Generator才訓練一次。

那這篇文章是說給discriminator多一點learning rate(2～5倍 e.g. G lr = 0.001 Dlr = 0.005)， 

也是達到差不多的效果。

# 成果

![](/assets/img/2018-06-15-SAGAN/table-1.png)

![](/assets/img/2018-06-15-SAGAN/table-2.png)

結果不錯呢!

其實他有幾個圖表在探討上方提到的2個trick，

如果有興趣的話就自己去翻論文吧～

![](/assets/img/2018-06-15-SAGAN/final-result.png)

最後這個結果作者給了一些挺有意思的說明，

首先說明一下這張圖，

每一格的最左邊是照片，上方都會有一些點，

每個點會經過一個attention輸出結果(右邊3張圖)。

- 藍框
	- 紅點:清楚地將鳥的身體依照顏色用attention分了出來。
	- 綠點:將背景的綠色顯現出來，甚至是穿過了鳥！！！
	- 藍點:翅膀。
- 紅框
	- 藍點：將前腳清楚的劃分出來
- 黃框
	- 紅點：作者說這個展示出把背景劃分出來的能力，儘管顏色都不同。不知道各位怎麼看，我是覺得這個有點太浮誇。




# 參考資料：

[Spectral normalization for both generator and discriminator]

[Spectral normalization openreview]

[Gans trained by a two time-scale update rule converge to a local nash equilibrium]

[Self-Attention Generative Adversarial Networks]

[Self-Attention Generative Adversarial Networks]:https://arxiv.org/abs/1805.08318
[Grad-CAM簡介]:https://xiaosean.github.io/deep%20learning/computer%20vision/2018/06/04/Grad-CAM/
[Spectral normalization for both generator and discriminator]:https://arxiv.org/abs/1802.05957
[Spectral normalization openreview]:https://openreview.net/forum?id=B1QRgziT-
[Gans trained by a two time-scale update rule converge to a local nash equilibrium]:https://arxiv.org/abs/1706.08500
